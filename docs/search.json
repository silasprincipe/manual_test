[
  {
    "objectID": "intro.html#guidelines-on-the-sharing-and-use-of-data-in-obis",
    "href": "intro.html#guidelines-on-the-sharing-and-use-of-data-in-obis",
    "title": "1  Introduction",
    "section": "1.1 Guidelines on the sharing and use of data in OBIS",
    "text": "1.1 Guidelines on the sharing and use of data in OBIS\nIt is important that our data providers as well as all the data users are aware and agree on the OBIS guidelines on the sharing and use of data in OBIS, which was adoped at the 4th OBIS Steering Group."
  },
  {
    "objectID": "intro.html#acknowledgements",
    "href": "intro.html#acknowledgements",
    "title": "1  Introduction",
    "section": "1.2 Acknowledgements",
    "text": "1.2 Acknowledgements\nThis manual received contributions from: Leen Vandepitte, Mary Kennedy, Philip Goldstein, Pieter Provoost, Samuel Bosch, Ward Appeltans, Abby Benson, Yi-Ming Gan, Carolina Peralta Brichtova, Saara Suominen, Serita van der Wal, and Elizabeth Lawrence."
  },
  {
    "objectID": "intro.html#data-policy",
    "href": "intro.html#data-policy",
    "title": "1  Introduction",
    "section": "1.3 Data Policy",
    "text": "1.3 Data Policy\n\n1.3.1 Guidelines on the sharing and use of data in OBIS\nAdopted at SG-OBIS-IV (Feb 2015) and IODE-XXIII (March 2015).\nThe OBIS data policy is based on the principles of timely, free and unrestricted access to biodiversity data for the benefit of science and society, as defined in the:\n\nIOC data exchange policy\nIOC guidelines on transfer of marine technology\nIODE objectives\nOBIS vision and mission\n\nUnless data are collected through activities funded by IOC/IODE, neither UNESCO, IOC, IODE, the OBIS Secretariat, nor its employees or contractors, own the data in OBIS and they take no responsibility for the quality of data or products based on OBIS, or the use or misuse that people may make of them nor can it control or limit the use of any data or products accessible through its website, other than through the use of a published Data Sharing and Use Terms and Conditions.\n\n1.3.1.1 Data sharing agreement\nThe data providers retain all rights and responsibilities associated with the data they make available to OBIS via the OBIS nodes. The OBIS nodes warrant that they have made the necessary agreements with the original data providers that it can make the data available to OBIS data under the Creative Commons licenses.\nThe data providers are responsible for the completeness of the data and metadata profiles. When data is made available to OBIS, OBIS is granted permission to:\n\nDistribute the data via its data and information portal\nBuild an integrated database, use the data for data quality control purposes, complement the data with other data such as climate variables and build value-added information products and services for science and decision-making\nServe the data to other similar open-access networks such as GBIF in compliance with the terms and conditions for use set by the data providers.\n\nIn pursuance of copyright compliance, OBIS endeavours to secure permission from rights holders to ingest their datasets. In the event that the inclusion of a dataset in OBIS is challenged on the basis of copyright infringement, OBIS will follow a take-down policy until there is resolution.\n\n\n1.3.1.2 Data use agreement\nThe data in OBIS are freely available to everyone, following the principles of equitable access and benefit sharing and supporting capacity development and participation of all IOC Member States in global programmes. However, data users are expected to give attribution to the data providers (see Citations) and the use of data from OBIS should happen in the light of fair use, i.e.:\n\nRecognize that the OBIS portal holds the master copy of the integrated database and hence users should refrain from online redistribution of the OBIS database. Because the OBIS database is updated regularly (every so months) with new datasets and revisions of existing datasets, copies of the OBIS database will become out of date quickly. If you wish to build access web services on top of OBIS, please contact the OBIS secretariat.\nRespect the data providers, and provide helpful feedback on data quality.\nIn the case you are a custodian of biogeographic data yourself you should take action to also publish these data through OBIS.\nConsider sponsoring or partnering with OBIS and its OBIS nodes in grant proposal writing. Creating a global database like OBIS cannot happen without the, often voluntary, contribution of many scientists and data managers all over the world. Several activities, such as the coordination, data aggregation, quality control, database and website maintenance require resources including manpower at national and international level. A list of sponsors can be found here\n\n\n\n1.3.1.3 Disclaimer\nAppropriate caution is necessary in the interpretation of results derived from OBIS. Users must recognize that the analysis and interpretation of data require background knowledge and expertise about marine biodiversity (including ecosystems and taxonomy). Users should be aware of possible errors, including in the use of species names, geo-referencing, data handling, and mapping. They should crosscheck their results for possible errors, and qualify their interpretation of any results accordingly.\nUnless data are collected through activities funded by IOC/IODE, neither UNESCO, IOC, IODE, the OBIS Secretariat, nor its employees or contractors, own the data in OBIS and they take no responsibility for the quality of data or products based on OBIS, or the use or misuse."
  },
  {
    "objectID": "intro.html#getting-help-in-obis",
    "href": "intro.html#getting-help-in-obis",
    "title": "1  Introduction",
    "section": "1.4 Getting Help in OBIS",
    "text": "1.4 Getting Help in OBIS\nIf you require additional assistance with OBIS we recommend you first get in touch with the most relevant OBIS node. We also have a support channel on Slack where you can communicate with the OBIS community for help. Please feel comfortable posting to this channel before reaching out to the OBIS Secretariat (helpdesk@obis.org). The OBIS community is quite active on Slack and GithHub (see below) so you are more likely to receive a quick answer to your question by posting in either place, as the Secretariat receives many requests.\nYou can submit issues and questions on relevant Github repositories:\n\nOBIS Manual\nOBIS issues GitHub repo\nOBIS quality control issues\nAll other OBIS repositories\n\nWe strongly recommend creating a GitHub account to engage with the OBIS community, document issues, ask questions, find datasets that need endorsing, etc. GitHub gives threads a more permanent home and allows for open communication and transparency. If you are unfamiliar with GitHub, the Carpentries have these training resources which you can reference."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "packages.html",
    "href": "packages.html",
    "title": "Packages",
    "section": "",
    "text": "Python packages\n\n\nEnable the download of data from OBIS\n\n\n\n\n\n\n\n\n\n\n\nR packages\n\n\nEnable the download of data from OBIS\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "packages/r/index.html",
    "href": "packages/r/index.html",
    "title": "R packages",
    "section": "",
    "text": "robis\nrobis, our flagship R package, is a client for the OBIS API. It includes functions for data access, as well as a few helper functions for visualizing occurrence data and extracting nested MeasurementOrFact or DNADerivedData records.\nAvailable through CRAN (use install.packages(“robis”)) GitHub: https://github.com/iobis/robis"
  },
  {
    "objectID": "tutorials.html",
    "href": "tutorials.html",
    "title": "Tutorials",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nUsing the Parquet format with OBIS data\n\n\n\n\n\nWorking with large datasets can be hard due to memory constraints, but using Parquet files can make it possible.\n\n\n\n\n\n\nAug 1, 2023\n\n\nSilas Principe\n\n\n4 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "obis-tutorials",
    "section": "",
    "text": "Go to manual."
  },
  {
    "objectID": "find-dwc.html",
    "href": "find-dwc.html",
    "title": "Find your DwC",
    "section": "",
    "text": "Darwin Core (DwC) is a body of standards (i.e., identifiers, labels, definitions) that facilitate sharing biodiversity informatics. It provides stable terms and vocabularies related to biological objects/data and their collection.\nDwC is meant to be used from the beginning of your research and is an excellent way of organizing and standardizing your data. All data submitted to OBIS must follow the Darwin Core guidelines. Whether you are planning your project or preparing to submit your data to an OBIS node, a key question is on what type of structure your data fits and what DwC terms are relevant (and necessary). Considering that, we prepared this quick tool to explore the option most suited to your case.\nYou may also want to explore our extensive documentation in the OBIS manual, which provide more in-depth details, or this quick decision tree created by Elizabeth Lawrence.\n\nFinding my schema\n\n  \n  \n  \n  \n  \n  \n\n  \n  \n    \n      What kind of data do you have, or will collect?\n       Occurrence\n       Abundance/Percent cover\n       Biomass\n       Habitat\n       Tracking\n       Genetic\n    \n    \n    \n    \n    \n    \n      \n      You don't have genetic data ⇢\n      Will this be a recurring sampling event OR can you aggregate your data in a single event?\n      A recurring sampling is any sampling that will occur in more than one time step. You can also have a single sampling, but have information that is relative to all your data (e.g. all collected on the same place). Note that many datasets can possibly be grouped in an event.\n             Yes\n       No\n    \n\n    \n    \n      \n      You don't have genetic data ⇢\n      This will be a recurring event or can be aggregated into an event ⇢\n      Have (or will) you collect any data associated with samples or sampling?\n      Examples of associated data are temperature, length of specimen, etc.\n             Yes\n       No\n    \n\n    \n    \n      \n      You don't have genetic data ⇢\n      This will be a recurring event or can be aggregated into an event ⇢\n      You collected associated data ⇢\n      \n      + You will also need:\n      \n    \n\n    \n    \n      \n      You don't have genetic data ⇢\n      This will be a recurring event or can be aggregated into an event ⇢\n      You have not collected associated data ⇢\n      \n    \n\n    \n    \n      \n      You don't have genetic data ⇢\n      This will not be a recurring event or can't be aggregated into an event ⇢\n      Have (or will) you collect any data associated with samples or sampling?\n      Examples of associated data are temperature, length of specimen, etc.\n             Yes\n       No\n    \n\n    \n    \n      \n      You don't have genetic data ⇢\n      This will not be a recurring event or can't be aggregated into an event ⇢\n      You collected associated data ⇢\n      \n      + You will also need:\n      \n    \n\n    \n    \n      \n      You don't have genetic data ⇢\n      This will not be a recurring event or can't be aggregated into an event ⇢\n      You have not collected associated data ⇢\n      \n    \n\n    \n    \n    \n    \n      \n      You have genetic data ⇢\n      Have (or will) you collect any data associated with samples or sampling?\n      Examples of associated data are temperature, length of specimen, etc.\n             Yes\n       No\n    \n    \n    \n    \n      \n      You have genetic data ⇢\n      You collected associated data ⇢\n      \n      + You will also need:\n      \n      \n      \n    \n\n    \n    \n      \n      You have genetic data ⇢\n      You have not collected associated data ⇢\n      \n      + You will also need:\n      \n    \n    \n    \n    \n    Restart"
  },
  {
    "objectID": "packages/python/index.html",
    "href": "packages/python/index.html",
    "title": "Python packages",
    "section": "",
    "text": "robis\nrobis, our flagship R package, is a client for the OBIS API. It includes functions for data access, as well as a few helper functions for visualizing occurrence data and extracting nested MeasurementOrFact or DNADerivedData records.\nAvailable through CRAN (use install.packages(“robis”)) GitHub: https://github.com/iobis/robis"
  },
  {
    "objectID": "tutorials/arrow-obis-2023-09-08/index.html",
    "href": "tutorials/arrow-obis-2023-09-08/index.html",
    "title": "Using the Parquet format with OBIS data",
    "section": "",
    "text": "What is Parquet?\nParquet is a lightweight format designed for columnar storage. Its main difference when compared to other formats like csv is that Parquet is column-oriented (while csv is row-oriented). This means that Parquet is much more efficient for data accessing.To illustrate, consider the scenario of extracting data from a specific column in a CSV file. This operation entails reading through all rows across all columns. In contrast, Parquet enables selective access solely to the required column, minimizing unnecessary data retrieval. Also very important: Parquet files are several times lighter than csv files, improving storage and sharing of data. You can learn more about Parquet here.\n\n\n\nimage 1\n\n\nThe Arrow package enable to work with Parquet files (as well some other interesting formats) within R. You can read the full documentation of the package here.\nWe will now see how you can use Parquet in your data analysis workflow. Note that the real advantage of Parquet comes when working with large datasets, specially those that you can’t load into memory.\n\n\nReading and writing Parquet files\nOpening a Parquet file is similar to opening a csv, and is done through the function read_parquet. We will start working with a small dataset containing records from OBIS for a fiddler crab species (Leptuca thayeri) which you can download here.\n\nlibrary(arrow) # To open the parquet files\nlibrary(dplyr) # For data manipulation\n\nspecies &lt;- read_parquet(\"leptuca_thayeri.parquet\")\n\nhead(species)\n\n# A tibble: 6 × 127\n  basisOfRecord     class       continent country countryCode county datasetName\n  &lt;chr&gt;             &lt;chr&gt;       &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;       &lt;chr&gt;  &lt;chr&gt;      \n1 HumanObservation  Malacostra… América … Colomb… CO          San A… Epifauna m…\n2 HumanObservation  Malacostra… América … Colomb… CO          San A… Epifauna m…\n3 PreservedSpecimen Malacostra… &lt;NA&gt;      Brazil  &lt;NA&gt;        Paran… &lt;NA&gt;       \n4 HumanObservation  Malacostra… América … Colomb… CO          San A… Epifauna m…\n5 HumanObservation  Malacostra… América … Colomb… CO          San A… Epifauna m…\n6 HumanObservation  Malacostra… América … Colomb… CO          San A… Epifauna m…\n# ℹ 120 more variables: dateIdentified &lt;chr&gt;, day &lt;chr&gt;, decimalLatitude &lt;dbl&gt;,\n#   decimalLongitude &lt;dbl&gt;, establishmentMeans &lt;chr&gt;, eventDate &lt;chr&gt;,\n#   eventID &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, geodeticDatum &lt;chr&gt;,\n#   georeferenceVerificationStatus &lt;chr&gt;, georeferencedBy &lt;chr&gt;,\n#   georeferencedDate &lt;chr&gt;, habitat &lt;chr&gt;, higherClassification &lt;chr&gt;,\n#   identifiedBy &lt;chr&gt;, identifiedByID &lt;chr&gt;, institutionCode &lt;chr&gt;,\n#   institutionID &lt;chr&gt;, kingdom &lt;chr&gt;, language &lt;chr&gt;, locality &lt;chr&gt;, …\n\n\nAs you can see, the returned object is a tibble and you can work with it as any other regular data frame. So, for example, to get all records from Brazil, we can simply use this:\n\nspecies_br &lt;- species %&gt;%\n  filter(country == \"Brazil\")\n\nhead(species_br, 2)\n\n# A tibble: 2 × 127\n  basisOfRecord     class       continent country countryCode county datasetName\n  &lt;chr&gt;             &lt;chr&gt;       &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;       &lt;chr&gt;  &lt;chr&gt;      \n1 PreservedSpecimen Malacostra… &lt;NA&gt;      Brazil  &lt;NA&gt;        Paran… &lt;NA&gt;       \n2 PreservedSpecimen Malacostra… &lt;NA&gt;      Brazil  &lt;NA&gt;        Mucuri &lt;NA&gt;       \n# ℹ 120 more variables: dateIdentified &lt;chr&gt;, day &lt;chr&gt;, decimalLatitude &lt;dbl&gt;,\n#   decimalLongitude &lt;dbl&gt;, establishmentMeans &lt;chr&gt;, eventDate &lt;chr&gt;,\n#   eventID &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, geodeticDatum &lt;chr&gt;,\n#   georeferenceVerificationStatus &lt;chr&gt;, georeferencedBy &lt;chr&gt;,\n#   georeferencedDate &lt;chr&gt;, habitat &lt;chr&gt;, higherClassification &lt;chr&gt;,\n#   identifiedBy &lt;chr&gt;, identifiedByID &lt;chr&gt;, institutionCode &lt;chr&gt;,\n#   institutionID &lt;chr&gt;, kingdom &lt;chr&gt;, language &lt;chr&gt;, locality &lt;chr&gt;, …\n\n\nSaving a data frame to Parquet is also simple, and is done through the write_parquet function:\n\nwrite_parquet(species_br, \"leptuca_thayeri_br.parquet\")\n\n\n\nOpening larger-than-memory files\nWhile using Parquet files for smaller datasets is also relevant (remember: it’s several times lighter!), the real power of Parquet (and Arrow) is the ability to work with large datasets without the need to load all the data to memory. Suppose you want to get the number of records available on OBIS for each Teleostei species. This would involve loading all the OBIS database in the memory before filtering the data. If you ever tried that, it’s quite probable that your R crashed. However, with Arrow this is a straightforward task.\nFor this part of the tutorial, we will work with the full export of the OBIS database which you can download here: https://obis.org/data/access/. The file have ~15GB.\n\nobis_file &lt;- \"obis_20230726.parquet\" # The path to the file\n\nThis time, instead of using read_parquet we will use the function open_dataset. The function will not read all the file into memory, but will instead read a “schema” showing how the file is organized.\n\nobis &lt;- open_dataset(obis_file)\n\nIf you print the obis object you will see that it is not a data frame, but instead a FileSytemDataset object, showing the columns of the table with their respective data types. So how can we access the data? Arrow support dplyr verbs that enable us to work with the data without loading it. So in our case we can filter the data as usual:\n\nteleostei &lt;- obis %&gt;%\n  filter(class == \"Teleostei\") %&gt;%\n  filter(taxonRank == \"Species\") %&gt;%\n  group_by(species) %&gt;%\n  summarise(records = n()) %&gt;%\n  collect()\n\nhead(teleostei)\n\n# A tibble: 6 × 2\n  species                records\n  &lt;chr&gt;                    &lt;int&gt;\n1 Halosaurus carinicauda       6\n2 Prognichthys glaphyrae      22\n3 Ogcocephalus nasutus       407\n4 Sebastes constellatus      142\n5 Oxyurichthys lonchotus      41\n6 Malacocottus kincaidi     1772\n\n\nDepending on the filters it may take a few seconds before the data is returned. Note that after all the filters we added collect(), what indicates to Arrow that it should process our request. Several dplyr verbs are available to use with Arrow, a full list can be found here.\nWhen working with large datasets, it’s important that your filter produces an object of reasonable size (i.e., that after collect() can be loaded in memory).\nIf you need to inspect the data before filtering, its possible to load only a slice of the data with slice_head:\n\nobis %&gt;%\n  select(class, taxonRank, species) %&gt;% # Select just a few columns\n  slice_head(n = 5) %&gt;% # Select the first 5 lines\n  collect() # Process the request\n\n# A tibble: 5 × 3\n  class     taxonRank species               \n  &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;                 \n1 Teleostei Species   Sebastes maliger      \n2 Teleostei Species   Pycnochromis acares   \n3 Teleostei Species   Pycnochromis acares   \n4 Teleostei Species   Pycnochromis acares   \n5 Teleostei Species   Gymnothorax fimbriatus\n\n\n\n\nLearning more\nThis tutorial barely scratches the surface of the full potential of working with Parquet. For example, it’s possible to save Parquet datasets in a way that only certain parts of the data need to be read, what can improve even more the computation. The better place to learn more about Arrow is the package website which contain several useful articles - https://arrow.apache.org/docs/dev/r/index.html\nYou can also see this tutorial on using Parquet with GBIF data: https://data-blog.gbif.org/post/apache-arrow-and-parquet/"
  }
]
